{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CNTK backend\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import os \n",
    "os.environ['KERAS_BACKEND'] = 'cntk'\n",
    "import requests\n",
    "import subprocess\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout, LSTM, GRU, Bidirectional, TimeDistributed\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras import initializers, regularizers, optimizers\n",
    "from keras.callbacks import History, CSVLogger, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/AMiner-Paper.txt\", \"r\")\n",
    "data=[]\n",
    "for x in f:\n",
    "  data=f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24206330/24206330 [00:20<00:00, 1168444.78it/s]\n"
     ]
    }
   ],
   "source": [
    "data_i=[]\n",
    "temp=[]\n",
    "for string in tqdm(data):\n",
    "    if string != '\\n':\n",
    "        temp.append(string)\n",
    "    else:\n",
    "        data_i.append(temp)\n",
    "        temp=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2092356/2092356 [00:04<00:00, 449259.97it/s]\n"
     ]
    }
   ],
   "source": [
    "processed_data=[]\n",
    "for dp in tqdm(data_i):\n",
    "    for string in dp:\n",
    "        if(string[:2]=='#!'):\n",
    "            processed_data.append(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1534970/1534970 [00:08<00:00, 172709.71it/s]\n"
     ]
    }
   ],
   "source": [
    "abs_list=[]\n",
    "c_list=[]\n",
    "for dp in tqdm(processed_data):\n",
    "    for string in dp:\n",
    "        if(string[:2]=='#c'):\n",
    "            c_list.append(string[3:].strip('\\n'))\n",
    "        if(string[:2]=='#!'):\n",
    "            abs_list.append(string[3:].strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame(data={'abstract': abs_list, 'pv': c_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = all_data.groupby('pv').filter(lambda x: len(x) >= 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_points=len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "shuffled = all_data.iloc[np.random.permutation(data_points), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=shuffled[:int(data_points*0.9)]\n",
    "test_data=shuffled[int(data_points*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as p\n",
    "p.dump(train_data,open(\"data/train.p\",\"wb\"))\n",
    "p.dump(test_data,open(\"data/test.p\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LENGTH = 25\n",
    "MAX_SENTS = 10\n",
    "MAX_NB_WORDS = 6000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/asr/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/asr/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "100%|██████████| 187566/187566 [07:28<00:00, 417.89it/s]\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl=WordNetLemmatizer()\n",
    "nltk.download('punkt')\n",
    "\n",
    "reviews = []\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "# for idx in range(train_data.shape[0]):\n",
    "#     text = train_data['abstract'].iloc[idx]\n",
    "#     texts.append(text)\n",
    "#     sentences = nltk.tokenize.sent_tokenize(text)\n",
    "#     reviews.append(sentences)\n",
    "#     labels.append(train_data['pv'].iloc[idx])\n",
    "\n",
    "\n",
    "for idx in tqdm(range(train_data.shape[0])):\n",
    "    text = train_data['abstract'].iloc[idx]\n",
    "#     tokens=nltk.tokenize.work_tokenize\n",
    "#     texts.append(text)\n",
    "    sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    l_sentences=[]\n",
    "    for sentence in (sentences):\n",
    "        sent_tokens=nltk.tokenize.word_tokenize(sentence)\n",
    "        l_sent_tokens=[]\n",
    "        for token in (sent_tokens):\n",
    "            l_sent_tokens.append(wnl.lemmatize(token))\n",
    "            l_sent_tokens.append(\" \")\n",
    "        l_sentence=\"\".join(l_sent_tokens)\n",
    "        l_sentences.append(l_sentence)\n",
    "    reviews.append(l_sentences)\n",
    "    texts.append(\" \".join(l_sentences))\n",
    "    labels.append(train_data['pv'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164800"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.zeros((len(texts), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "doc_lst = []\n",
    "\n",
    "for i, sentences in enumerate(reviews):\n",
    "    for j, sent in enumerate(sentences):\n",
    "        if j < MAX_SENTS:\n",
    "            wordTokens = text_to_word_sequence(sent)\n",
    "#             print(wordTokens)\n",
    "            k = 0\n",
    "            words_in_sent = []\n",
    "            for _, word in enumerate(wordTokens):\n",
    "                if k < MAX_SENT_LENGTH: \n",
    "                    if (word in tokenizer.word_index) and (tokenizer.word_index[word] < MAX_NB_WORDS):\n",
    "                        data[i, j, k] = tokenizer.word_index[word]\n",
    "                        words_in_sent.append(word)\n",
    "                    else:\n",
    "                        data[i, j, k] = MAX_NB_WORDS\n",
    "                        words_in_sent.append('UNK')\n",
    "                    k = k + 1\n",
    "            doc_lst.append(words_in_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 164800 unique tokens.\n",
      "Shape of data tensor: (187566, 10, 25)\n",
      "Shape of label tensor: (187566, 54)\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Total %s unique tokens.' % len(word_index))\n",
    "\n",
    "y_train = to_categorical(np.asarray(integer_encoded)).astype('float32')\n",
    "x_train = data\n",
    "\n",
    "print('Shape of data tensor:', x_train.shape)\n",
    "print('Shape of label tensor:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20841/20841 [00:49<00:00, 419.59it/s]\n"
     ]
    }
   ],
   "source": [
    "test_reviews = []\n",
    "test_labels = []\n",
    "test_texts = []\n",
    "\n",
    "# for idx in range(test_data.shape[0]):\n",
    "#     text = test_data['abstract'].iloc[idx]\n",
    "#     test_texts.append(text)\n",
    "#     sentences = nltk.tokenize.sent_tokenize(text)\n",
    "#     test_reviews.append(sentences)\n",
    "#     test_labels.append(test_data['pv'].iloc[idx])\n",
    "    \n",
    "    \n",
    "for idx in tqdm(range(test_data.shape[0])):\n",
    "    text = test_data['abstract'].iloc[idx]\n",
    "#     tokens=nltk.tokenize.work_tokenize\n",
    "#     texts.append(text)\n",
    "    sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    l_sentences=[]\n",
    "    for sentence in (sentences):\n",
    "        sent_tokens=nltk.tokenize.word_tokenize(sentence)\n",
    "        l_sent_tokens=[]\n",
    "        for token in (sent_tokens):\n",
    "            l_sent_tokens.append(wnl.lemmatize(token))\n",
    "            l_sent_tokens.append(\" \")\n",
    "        l_sentence=\"\".join(l_sent_tokens)\n",
    "        l_sentences.append(l_sentence)\n",
    "    test_reviews.append(l_sentences)\n",
    "    test_texts.append(\" \".join(l_sentences))\n",
    "    test_labels.append(test_data['pv'].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = np.zeros((len(test_texts), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "\n",
    "for i, sentences in enumerate(test_reviews):\n",
    "    for j, sent in enumerate(sentences):\n",
    "        if j < MAX_SENTS:\n",
    "            wordTokens = text_to_word_sequence(sent)\n",
    "            k = 0\n",
    "            words_in_sent = []\n",
    "            for _, word in enumerate(wordTokens):\n",
    "                if k < MAX_SENT_LENGTH: \n",
    "                    if (word in tokenizer.word_index) and (tokenizer.word_index[word] < MAX_NB_WORDS):\n",
    "                        data2[i, j, k] = tokenizer.word_index[word]\n",
    "                        words_in_sent.append(word)\n",
    "                    else:\n",
    "                        data2[i, j, k] = MAX_NB_WORDS\n",
    "                        words_in_sent.append('UNK')\n",
    "                    k = k + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_integer_encoded = label_encoder.transform(test_labels)\n",
    "y_test = to_categorical(np.asarray(test_integer_encoded)).astype('float32')\n",
    "x_test = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-21 09:12:21,315 : INFO : collecting all words and their counts\n",
      "2019-04-21 09:12:21,315 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-04-21 09:12:21,348 : INFO : PROGRESS: at sentence #10000, processed 196572 words, keeping 5594 word types\n",
      "2019-04-21 09:12:21,380 : INFO : PROGRESS: at sentence #20000, processed 393666 words, keeping 5925 word types\n",
      "2019-04-21 09:12:21,412 : INFO : PROGRESS: at sentence #30000, processed 590634 words, keeping 5983 word types\n",
      "2019-04-21 09:12:21,445 : INFO : PROGRESS: at sentence #40000, processed 786750 words, keeping 5994 word types\n",
      "2019-04-21 09:12:21,477 : INFO : PROGRESS: at sentence #50000, processed 983657 words, keeping 5997 word types\n",
      "2019-04-21 09:12:21,509 : INFO : PROGRESS: at sentence #60000, processed 1180753 words, keeping 5998 word types\n",
      "2019-04-21 09:12:21,541 : INFO : PROGRESS: at sentence #70000, processed 1376987 words, keeping 5999 word types\n",
      "2019-04-21 09:12:21,573 : INFO : PROGRESS: at sentence #80000, processed 1573389 words, keeping 5999 word types\n",
      "2019-04-21 09:12:21,605 : INFO : PROGRESS: at sentence #90000, processed 1769690 words, keeping 5999 word types\n",
      "2019-04-21 09:12:21,638 : INFO : PROGRESS: at sentence #100000, processed 1965594 words, keeping 6000 word types\n",
      "2019-04-21 09:12:21,670 : INFO : PROGRESS: at sentence #110000, processed 2163290 words, keeping 6000 word types\n",
      "2019-04-21 09:12:21,703 : INFO : PROGRESS: at sentence #120000, processed 2360737 words, keeping 6000 word types\n",
      "2019-04-21 09:12:21,736 : INFO : PROGRESS: at sentence #130000, processed 2556691 words, keeping 6000 word types\n",
      "2019-04-21 09:12:21,768 : INFO : PROGRESS: at sentence #140000, processed 2752762 words, keeping 6000 word types\n",
      "2019-04-21 09:12:21,801 : INFO : PROGRESS: at sentence #150000, processed 2949138 words, keeping 6000 word types\n",
      "2019-04-21 09:12:21,833 : INFO : PROGRESS: at sentence #160000, processed 3145486 words, keeping 6000 word types\n",
      "2019-04-21 09:12:21,865 : INFO : PROGRESS: at sentence #170000, processed 3341896 words, keeping 6000 word types\n",
      "2019-04-21 09:12:21,897 : INFO : PROGRESS: at sentence #180000, processed 3536991 words, keeping 6000 word types\n",
      "2019-04-21 09:12:21,930 : INFO : PROGRESS: at sentence #190000, processed 3733671 words, keeping 6000 word types\n",
      "2019-04-21 09:12:21,962 : INFO : PROGRESS: at sentence #200000, processed 3930851 words, keeping 6000 word types\n",
      "2019-04-21 09:12:21,993 : INFO : PROGRESS: at sentence #210000, processed 4127870 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,025 : INFO : PROGRESS: at sentence #220000, processed 4324611 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,057 : INFO : PROGRESS: at sentence #230000, processed 4522465 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,089 : INFO : PROGRESS: at sentence #240000, processed 4720365 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,121 : INFO : PROGRESS: at sentence #250000, processed 4917541 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,155 : INFO : PROGRESS: at sentence #260000, processed 5114310 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,187 : INFO : PROGRESS: at sentence #270000, processed 5311419 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,219 : INFO : PROGRESS: at sentence #280000, processed 5508599 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,251 : INFO : PROGRESS: at sentence #290000, processed 5705986 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,283 : INFO : PROGRESS: at sentence #300000, processed 5902890 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,315 : INFO : PROGRESS: at sentence #310000, processed 6100497 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,348 : INFO : PROGRESS: at sentence #320000, processed 6297371 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,380 : INFO : PROGRESS: at sentence #330000, processed 6495232 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,412 : INFO : PROGRESS: at sentence #340000, processed 6692153 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,445 : INFO : PROGRESS: at sentence #350000, processed 6889387 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,478 : INFO : PROGRESS: at sentence #360000, processed 7085437 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,512 : INFO : PROGRESS: at sentence #370000, processed 7283135 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,545 : INFO : PROGRESS: at sentence #380000, processed 7481137 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,577 : INFO : PROGRESS: at sentence #390000, processed 7677509 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,611 : INFO : PROGRESS: at sentence #400000, processed 7874492 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,643 : INFO : PROGRESS: at sentence #410000, processed 8071369 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,675 : INFO : PROGRESS: at sentence #420000, processed 8267963 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,708 : INFO : PROGRESS: at sentence #430000, processed 8464351 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,742 : INFO : PROGRESS: at sentence #440000, processed 8661370 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,774 : INFO : PROGRESS: at sentence #450000, processed 8857285 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,806 : INFO : PROGRESS: at sentence #460000, processed 9054457 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,840 : INFO : PROGRESS: at sentence #470000, processed 9251824 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,874 : INFO : PROGRESS: at sentence #480000, processed 9448838 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,907 : INFO : PROGRESS: at sentence #490000, processed 9646502 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,940 : INFO : PROGRESS: at sentence #500000, processed 9842947 words, keeping 6000 word types\n",
      "2019-04-21 09:12:22,972 : INFO : PROGRESS: at sentence #510000, processed 10040251 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,005 : INFO : PROGRESS: at sentence #520000, processed 10237358 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,038 : INFO : PROGRESS: at sentence #530000, processed 10434668 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,071 : INFO : PROGRESS: at sentence #540000, processed 10630540 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,104 : INFO : PROGRESS: at sentence #550000, processed 10828131 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,138 : INFO : PROGRESS: at sentence #560000, processed 11024811 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,171 : INFO : PROGRESS: at sentence #570000, processed 11221509 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,205 : INFO : PROGRESS: at sentence #580000, processed 11418449 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,238 : INFO : PROGRESS: at sentence #590000, processed 11614820 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,271 : INFO : PROGRESS: at sentence #600000, processed 11812229 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,304 : INFO : PROGRESS: at sentence #610000, processed 12008658 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,337 : INFO : PROGRESS: at sentence #620000, processed 12205732 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,370 : INFO : PROGRESS: at sentence #630000, processed 12401804 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,404 : INFO : PROGRESS: at sentence #640000, processed 12597735 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,437 : INFO : PROGRESS: at sentence #650000, processed 12794889 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,469 : INFO : PROGRESS: at sentence #660000, processed 12991920 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,502 : INFO : PROGRESS: at sentence #670000, processed 13188399 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,535 : INFO : PROGRESS: at sentence #680000, processed 13384153 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,568 : INFO : PROGRESS: at sentence #690000, processed 13580391 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,601 : INFO : PROGRESS: at sentence #700000, processed 13775851 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,634 : INFO : PROGRESS: at sentence #710000, processed 13972094 words, keeping 6000 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-21 09:12:23,668 : INFO : PROGRESS: at sentence #720000, processed 14168778 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,702 : INFO : PROGRESS: at sentence #730000, processed 14365453 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,736 : INFO : PROGRESS: at sentence #740000, processed 14563061 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,770 : INFO : PROGRESS: at sentence #750000, processed 14759694 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,804 : INFO : PROGRESS: at sentence #760000, processed 14957534 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,837 : INFO : PROGRESS: at sentence #770000, processed 15153904 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,870 : INFO : PROGRESS: at sentence #780000, processed 15351906 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,903 : INFO : PROGRESS: at sentence #790000, processed 15547649 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,936 : INFO : PROGRESS: at sentence #800000, processed 15745002 words, keeping 6000 word types\n",
      "2019-04-21 09:12:23,970 : INFO : PROGRESS: at sentence #810000, processed 15941409 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,003 : INFO : PROGRESS: at sentence #820000, processed 16138401 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,037 : INFO : PROGRESS: at sentence #830000, processed 16335489 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,070 : INFO : PROGRESS: at sentence #840000, processed 16531680 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,103 : INFO : PROGRESS: at sentence #850000, processed 16727914 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,136 : INFO : PROGRESS: at sentence #860000, processed 16925340 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,169 : INFO : PROGRESS: at sentence #870000, processed 17121371 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,202 : INFO : PROGRESS: at sentence #880000, processed 17318597 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,235 : INFO : PROGRESS: at sentence #890000, processed 17515617 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,268 : INFO : PROGRESS: at sentence #900000, processed 17711771 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,301 : INFO : PROGRESS: at sentence #910000, processed 17908603 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,334 : INFO : PROGRESS: at sentence #920000, processed 18105182 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,366 : INFO : PROGRESS: at sentence #930000, processed 18302134 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,399 : INFO : PROGRESS: at sentence #940000, processed 18498374 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,433 : INFO : PROGRESS: at sentence #950000, processed 18694526 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,466 : INFO : PROGRESS: at sentence #960000, processed 18891425 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,500 : INFO : PROGRESS: at sentence #970000, processed 19089546 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,533 : INFO : PROGRESS: at sentence #980000, processed 19286188 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,566 : INFO : PROGRESS: at sentence #990000, processed 19483266 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,599 : INFO : PROGRESS: at sentence #1000000, processed 19678810 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,632 : INFO : PROGRESS: at sentence #1010000, processed 19876858 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,665 : INFO : PROGRESS: at sentence #1020000, processed 20074035 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,698 : INFO : PROGRESS: at sentence #1030000, processed 20271691 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,731 : INFO : PROGRESS: at sentence #1040000, processed 20469054 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,764 : INFO : PROGRESS: at sentence #1050000, processed 20665188 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,797 : INFO : PROGRESS: at sentence #1060000, processed 20861176 words, keeping 6000 word types\n",
      "2019-04-21 09:12:24,825 : INFO : collected 6000 word types from a corpus of 21030083 raw words and 1068569 sentences\n",
      "2019-04-21 09:12:24,826 : INFO : Loading a fresh vocabulary\n",
      "2019-04-21 09:12:24,844 : INFO : effective_min_count=3 retains 6000 unique words (100% of original 6000, drops 0)\n",
      "2019-04-21 09:12:24,844 : INFO : effective_min_count=3 leaves 21030083 word corpus (100% of original 21030083, drops 0)\n",
      "2019-04-21 09:12:24,863 : INFO : deleting the raw counts dictionary of 6000 items\n",
      "2019-04-21 09:12:24,864 : INFO : sample=0.001 downsamples 35 most-common words\n",
      "2019-04-21 09:12:24,865 : INFO : downsampling leaves estimated 15072950 word corpus (71.7% of prior 21030083)\n",
      "2019-04-21 09:12:24,879 : INFO : estimated required memory for 6000 words and 100 dimensions: 7800000 bytes\n",
      "2019-04-21 09:12:24,880 : INFO : resetting layer weights\n",
      "2019-04-21 09:12:24,954 : INFO : training model with 16 workers on 6000 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-04-21 09:12:25,966 : INFO : EPOCH 1 - PROGRESS: at 7.08% examples, 1063332 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:12:26,971 : INFO : EPOCH 1 - PROGRESS: at 15.03% examples, 1127234 words/s, in_qsize 29, out_qsize 2\n",
      "2019-04-21 09:12:27,993 : INFO : EPOCH 1 - PROGRESS: at 23.24% examples, 1155943 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:28,996 : INFO : EPOCH 1 - PROGRESS: at 31.11% examples, 1163248 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:29,996 : INFO : EPOCH 1 - PROGRESS: at 39.23% examples, 1175367 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:30,999 : INFO : EPOCH 1 - PROGRESS: at 47.30% examples, 1181590 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:32,006 : INFO : EPOCH 1 - PROGRESS: at 55.42% examples, 1186463 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:33,023 : INFO : EPOCH 1 - PROGRESS: at 63.17% examples, 1181556 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:34,032 : INFO : EPOCH 1 - PROGRESS: at 70.74% examples, 1175646 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:35,037 : INFO : EPOCH 1 - PROGRESS: at 78.19% examples, 1170025 words/s, in_qsize 32, out_qsize 0\n",
      "2019-04-21 09:12:36,046 : INFO : EPOCH 1 - PROGRESS: at 85.79% examples, 1166827 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:37,052 : INFO : EPOCH 1 - PROGRESS: at 93.64% examples, 1167457 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:12:37,744 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-04-21 09:12:37,750 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-04-21 09:12:37,753 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-04-21 09:12:37,755 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-04-21 09:12:37,761 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-04-21 09:12:37,763 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-04-21 09:12:37,766 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-04-21 09:12:37,769 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-04-21 09:12:37,773 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-21 09:12:37,782 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-21 09:12:37,785 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-21 09:12:37,787 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-21 09:12:37,789 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-21 09:12:37,790 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-21 09:12:37,792 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-21 09:12:37,805 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-21 09:12:37,806 : INFO : EPOCH - 1 : training on 21030083 raw words (15072883 effective words) took 12.8s, 1173639 effective words/s\n",
      "2019-04-21 09:12:38,816 : INFO : EPOCH 2 - PROGRESS: at 7.41% examples, 1115926 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:39,824 : INFO : EPOCH 2 - PROGRESS: at 15.65% examples, 1173301 words/s, in_qsize 31, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-21 09:12:40,828 : INFO : EPOCH 2 - PROGRESS: at 23.91% examples, 1195701 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:41,834 : INFO : EPOCH 2 - PROGRESS: at 31.87% examples, 1195656 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:42,840 : INFO : EPOCH 2 - PROGRESS: at 40.13% examples, 1204427 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:43,854 : INFO : EPOCH 2 - PROGRESS: at 48.24% examples, 1205110 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:44,855 : INFO : EPOCH 2 - PROGRESS: at 56.46% examples, 1209602 words/s, in_qsize 29, out_qsize 2\n",
      "2019-04-21 09:12:45,862 : INFO : EPOCH 2 - PROGRESS: at 64.60% examples, 1210389 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:46,874 : INFO : EPOCH 2 - PROGRESS: at 73.01% examples, 1215157 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:12:47,883 : INFO : EPOCH 2 - PROGRESS: at 80.99% examples, 1212783 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:48,885 : INFO : EPOCH 2 - PROGRESS: at 89.27% examples, 1215610 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:12:49,892 : INFO : EPOCH 2 - PROGRESS: at 97.57% examples, 1217945 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:12:50,119 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-04-21 09:12:50,122 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-04-21 09:12:50,123 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-04-21 09:12:50,126 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-04-21 09:12:50,129 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-04-21 09:12:50,131 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-04-21 09:12:50,136 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-04-21 09:12:50,139 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-04-21 09:12:50,139 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-21 09:12:50,144 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-21 09:12:50,149 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-21 09:12:50,157 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-21 09:12:50,158 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-21 09:12:50,163 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-21 09:12:50,172 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-21 09:12:50,175 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-21 09:12:50,176 : INFO : EPOCH - 2 : training on 21030083 raw words (15075593 effective words) took 12.4s, 1219603 effective words/s\n",
      "2019-04-21 09:12:51,186 : INFO : EPOCH 3 - PROGRESS: at 7.37% examples, 1108131 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:52,195 : INFO : EPOCH 3 - PROGRESS: at 15.50% examples, 1161078 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:12:53,197 : INFO : EPOCH 3 - PROGRESS: at 23.67% examples, 1183770 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:54,202 : INFO : EPOCH 3 - PROGRESS: at 31.68% examples, 1188858 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:12:55,202 : INFO : EPOCH 3 - PROGRESS: at 39.70% examples, 1193061 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:56,202 : INFO : EPOCH 3 - PROGRESS: at 47.91% examples, 1200692 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:57,205 : INFO : EPOCH 3 - PROGRESS: at 56.08% examples, 1204656 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:58,211 : INFO : EPOCH 3 - PROGRESS: at 64.46% examples, 1210674 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:12:59,216 : INFO : EPOCH 3 - PROGRESS: at 72.48% examples, 1209938 words/s, in_qsize 29, out_qsize 2\n",
      "2019-04-21 09:13:00,216 : INFO : EPOCH 3 - PROGRESS: at 80.56% examples, 1210628 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:01,223 : INFO : EPOCH 3 - PROGRESS: at 88.79% examples, 1212464 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:13:02,246 : INFO : EPOCH 3 - PROGRESS: at 96.80% examples, 1209866 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:02,548 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-04-21 09:13:02,550 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-04-21 09:13:02,559 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-04-21 09:13:02,562 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-04-21 09:13:02,572 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-04-21 09:13:02,575 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-04-21 09:13:02,576 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-04-21 09:13:02,583 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-04-21 09:13:02,594 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-21 09:13:02,595 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-21 09:13:02,596 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-21 09:13:02,597 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-21 09:13:02,605 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-21 09:13:02,608 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-21 09:13:02,609 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-21 09:13:02,616 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-21 09:13:02,616 : INFO : EPOCH - 3 : training on 21030083 raw words (15074037 effective words) took 12.4s, 1212514 effective words/s\n",
      "2019-04-21 09:13:03,626 : INFO : EPOCH 4 - PROGRESS: at 7.32% examples, 1100478 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:04,632 : INFO : EPOCH 4 - PROGRESS: at 15.50% examples, 1163215 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:05,637 : INFO : EPOCH 4 - PROGRESS: at 23.62% examples, 1181177 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:13:06,644 : INFO : EPOCH 4 - PROGRESS: at 31.73% examples, 1189951 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:13:07,655 : INFO : EPOCH 4 - PROGRESS: at 39.85% examples, 1194296 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:13:08,666 : INFO : EPOCH 4 - PROGRESS: at 48.06% examples, 1199464 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:13:09,666 : INFO : EPOCH 4 - PROGRESS: at 56.22% examples, 1203922 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:10,674 : INFO : EPOCH 4 - PROGRESS: at 64.41% examples, 1206246 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:13:11,675 : INFO : EPOCH 4 - PROGRESS: at 72.58% examples, 1208860 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:12,675 : INFO : EPOCH 4 - PROGRESS: at 80.61% examples, 1208792 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:13:13,686 : INFO : EPOCH 4 - PROGRESS: at 88.84% examples, 1210440 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:13:14,696 : INFO : EPOCH 4 - PROGRESS: at 97.09% examples, 1212368 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:14,973 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-04-21 09:13:14,979 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-04-21 09:13:14,983 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-04-21 09:13:14,985 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-04-21 09:13:14,989 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-04-21 09:13:14,990 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-04-21 09:13:14,994 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-04-21 09:13:14,999 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-04-21 09:13:15,002 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-21 09:13:15,004 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-21 09:13:15,010 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-21 09:13:15,011 : INFO : worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-21 09:13:15,018 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-21 09:13:15,021 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-21 09:13:15,029 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-21 09:13:15,034 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-21 09:13:15,035 : INFO : EPOCH - 4 : training on 21030083 raw words (15072634 effective words) took 12.4s, 1214493 effective words/s\n",
      "2019-04-21 09:13:16,053 : INFO : EPOCH 5 - PROGRESS: at 7.27% examples, 1088597 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:13:17,062 : INFO : EPOCH 5 - PROGRESS: at 15.50% examples, 1158873 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:18,063 : INFO : EPOCH 5 - PROGRESS: at 23.53% examples, 1175246 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:19,067 : INFO : EPOCH 5 - PROGRESS: at 31.68% examples, 1188076 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:20,071 : INFO : EPOCH 5 - PROGRESS: at 39.80% examples, 1194608 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:21,077 : INFO : EPOCH 5 - PROGRESS: at 47.82% examples, 1195873 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:22,080 : INFO : EPOCH 5 - PROGRESS: at 55.56% examples, 1191281 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:23,085 : INFO : EPOCH 5 - PROGRESS: at 63.79% examples, 1196412 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:13:24,094 : INFO : EPOCH 5 - PROGRESS: at 72.06% examples, 1200663 words/s, in_qsize 29, out_qsize 2\n",
      "2019-04-21 09:13:25,099 : INFO : EPOCH 5 - PROGRESS: at 80.33% examples, 1204430 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:13:26,106 : INFO : EPOCH 5 - PROGRESS: at 88.50% examples, 1206201 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:27,110 : INFO : EPOCH 5 - PROGRESS: at 96.67% examples, 1207887 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:27,435 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-04-21 09:13:27,439 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-04-21 09:13:27,442 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-04-21 09:13:27,446 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-04-21 09:13:27,447 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-04-21 09:13:27,450 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-04-21 09:13:27,457 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-04-21 09:13:27,461 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-04-21 09:13:27,466 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-21 09:13:27,467 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-21 09:13:27,473 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-21 09:13:27,475 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-21 09:13:27,479 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-21 09:13:27,481 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-21 09:13:27,483 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-21 09:13:27,487 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-21 09:13:27,488 : INFO : EPOCH - 5 : training on 21030083 raw words (15072899 effective words) took 12.4s, 1211483 effective words/s\n",
      "2019-04-21 09:13:28,499 : INFO : EPOCH 6 - PROGRESS: at 7.41% examples, 1113503 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:29,507 : INFO : EPOCH 6 - PROGRESS: at 15.55% examples, 1164855 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:30,520 : INFO : EPOCH 6 - PROGRESS: at 23.67% examples, 1179158 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:31,530 : INFO : EPOCH 6 - PROGRESS: at 31.87% examples, 1191152 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:13:32,534 : INFO : EPOCH 6 - PROGRESS: at 39.99% examples, 1196962 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:33,535 : INFO : EPOCH 6 - PROGRESS: at 48.24% examples, 1204845 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:34,545 : INFO : EPOCH 6 - PROGRESS: at 56.18% examples, 1201842 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:35,547 : INFO : EPOCH 6 - PROGRESS: at 64.27% examples, 1203353 words/s, in_qsize 32, out_qsize 0\n",
      "2019-04-21 09:13:36,556 : INFO : EPOCH 6 - PROGRESS: at 72.35% examples, 1203674 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:37,562 : INFO : EPOCH 6 - PROGRESS: at 80.52% examples, 1205734 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:13:38,570 : INFO : EPOCH 6 - PROGRESS: at 88.79% examples, 1208405 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:39,580 : INFO : EPOCH 6 - PROGRESS: at 96.90% examples, 1208735 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:13:39,864 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-04-21 09:13:39,873 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-04-21 09:13:39,874 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-04-21 09:13:39,882 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-04-21 09:13:39,887 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-04-21 09:13:39,892 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-04-21 09:13:39,894 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-04-21 09:13:39,897 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-04-21 09:13:39,905 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-21 09:13:39,908 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-21 09:13:39,912 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-21 09:13:39,915 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-21 09:13:39,919 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-21 09:13:39,921 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-21 09:13:39,921 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-21 09:13:39,924 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-21 09:13:39,925 : INFO : EPOCH - 6 : training on 21030083 raw words (15072821 effective words) took 12.4s, 1212752 effective words/s\n",
      "2019-04-21 09:13:40,938 : INFO : EPOCH 7 - PROGRESS: at 7.08% examples, 1061173 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:41,939 : INFO : EPOCH 7 - PROGRESS: at 15.22% examples, 1142765 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:42,939 : INFO : EPOCH 7 - PROGRESS: at 23.34% examples, 1169456 words/s, in_qsize 32, out_qsize 0\n",
      "2019-04-21 09:13:43,940 : INFO : EPOCH 7 - PROGRESS: at 31.39% examples, 1181340 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:13:44,942 : INFO : EPOCH 7 - PROGRESS: at 39.51% examples, 1189287 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:45,948 : INFO : EPOCH 7 - PROGRESS: at 47.77% examples, 1197588 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:46,959 : INFO : EPOCH 7 - PROGRESS: at 55.85% examples, 1198493 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:47,960 : INFO : EPOCH 7 - PROGRESS: at 64.17% examples, 1205178 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:48,973 : INFO : EPOCH 7 - PROGRESS: at 72.39% examples, 1207025 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:49,975 : INFO : EPOCH 7 - PROGRESS: at 80.56% examples, 1209144 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:50,975 : INFO : EPOCH 7 - PROGRESS: at 88.60% examples, 1209234 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:13:51,978 : INFO : EPOCH 7 - PROGRESS: at 96.71% examples, 1210170 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:52,293 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-04-21 09:13:52,295 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-04-21 09:13:52,301 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-04-21 09:13:52,305 : INFO : worker thread finished; awaiting finish of 12 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-21 09:13:52,306 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-04-21 09:13:52,316 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-04-21 09:13:52,322 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-04-21 09:13:52,326 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-04-21 09:13:52,328 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-21 09:13:52,331 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-21 09:13:52,339 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-21 09:13:52,341 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-21 09:13:52,343 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-21 09:13:52,347 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-21 09:13:52,348 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-21 09:13:52,351 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-21 09:13:52,352 : INFO : EPOCH - 7 : training on 21030083 raw words (15072051 effective words) took 12.4s, 1213656 effective words/s\n",
      "2019-04-21 09:13:53,361 : INFO : EPOCH 8 - PROGRESS: at 7.27% examples, 1095786 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:54,364 : INFO : EPOCH 8 - PROGRESS: at 15.60% examples, 1172909 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:55,370 : INFO : EPOCH 8 - PROGRESS: at 23.58% examples, 1180354 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:56,385 : INFO : EPOCH 8 - PROGRESS: at 31.82% examples, 1192136 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:57,400 : INFO : EPOCH 8 - PROGRESS: at 39.94% examples, 1195102 words/s, in_qsize 29, out_qsize 2\n",
      "2019-04-21 09:13:58,401 : INFO : EPOCH 8 - PROGRESS: at 47.91% examples, 1196200 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:13:59,401 : INFO : EPOCH 8 - PROGRESS: at 55.99% examples, 1199010 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:14:00,406 : INFO : EPOCH 8 - PROGRESS: at 64.22% examples, 1203199 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:01,408 : INFO : EPOCH 8 - PROGRESS: at 72.39% examples, 1206122 words/s, in_qsize 32, out_qsize 1\n",
      "2019-04-21 09:14:02,409 : INFO : EPOCH 8 - PROGRESS: at 80.28% examples, 1204119 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:03,418 : INFO : EPOCH 8 - PROGRESS: at 87.93% examples, 1198537 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:04,421 : INFO : EPOCH 8 - PROGRESS: at 95.91% examples, 1198531 words/s, in_qsize 32, out_qsize 1\n",
      "2019-04-21 09:14:04,849 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-04-21 09:14:04,858 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-04-21 09:14:04,861 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-04-21 09:14:04,865 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-04-21 09:14:04,866 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-04-21 09:14:04,870 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-04-21 09:14:04,871 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-04-21 09:14:04,880 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-04-21 09:14:04,881 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-21 09:14:04,885 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-21 09:14:04,896 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-21 09:14:04,902 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-21 09:14:04,903 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-21 09:14:04,904 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-21 09:14:04,906 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-21 09:14:04,907 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-21 09:14:04,908 : INFO : EPOCH - 8 : training on 21030083 raw words (15071950 effective words) took 12.5s, 1201221 effective words/s\n",
      "2019-04-21 09:14:05,924 : INFO : EPOCH 9 - PROGRESS: at 7.27% examples, 1086697 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:06,930 : INFO : EPOCH 9 - PROGRESS: at 15.60% examples, 1166386 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:07,933 : INFO : EPOCH 9 - PROGRESS: at 23.76% examples, 1186617 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:08,934 : INFO : EPOCH 9 - PROGRESS: at 31.87% examples, 1195679 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:14:09,938 : INFO : EPOCH 9 - PROGRESS: at 40.04% examples, 1202180 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:10,941 : INFO : EPOCH 9 - PROGRESS: at 48.15% examples, 1205266 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:11,942 : INFO : EPOCH 9 - PROGRESS: at 56.13% examples, 1204836 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:14:12,952 : INFO : EPOCH 9 - PROGRESS: at 64.27% examples, 1205769 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:13,954 : INFO : EPOCH 9 - PROGRESS: at 72.48% examples, 1209047 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:14:14,956 : INFO : EPOCH 9 - PROGRESS: at 80.52% examples, 1208936 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:15,958 : INFO : EPOCH 9 - PROGRESS: at 88.60% examples, 1209396 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:16,960 : INFO : EPOCH 9 - PROGRESS: at 96.76% examples, 1210951 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:14:17,268 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-04-21 09:14:17,278 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-04-21 09:14:17,278 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-04-21 09:14:17,282 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-04-21 09:14:17,286 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-04-21 09:14:17,287 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-04-21 09:14:17,292 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-04-21 09:14:17,298 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-04-21 09:14:17,301 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-21 09:14:17,306 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-21 09:14:17,311 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-21 09:14:17,311 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-21 09:14:17,312 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-21 09:14:17,314 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-21 09:14:17,323 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-21 09:14:17,324 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-21 09:14:17,324 : INFO : EPOCH - 9 : training on 21030083 raw words (15072466 effective words) took 12.4s, 1214734 effective words/s\n",
      "2019-04-21 09:14:18,336 : INFO : EPOCH 10 - PROGRESS: at 6.89% examples, 1034248 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:19,337 : INFO : EPOCH 10 - PROGRESS: at 14.84% examples, 1114822 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:14:20,340 : INFO : EPOCH 10 - PROGRESS: at 23.10% examples, 1157300 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:21,349 : INFO : EPOCH 10 - PROGRESS: at 31.25% examples, 1172994 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:22,355 : INFO : EPOCH 10 - PROGRESS: at 39.52% examples, 1186190 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:23,361 : INFO : EPOCH 10 - PROGRESS: at 47.72% examples, 1193694 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:24,363 : INFO : EPOCH 10 - PROGRESS: at 55.85% examples, 1197731 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:25,366 : INFO : EPOCH 10 - PROGRESS: at 64.17% examples, 1204210 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:14:26,369 : INFO : EPOCH 10 - PROGRESS: at 72.39% examples, 1207541 words/s, in_qsize 31, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-21 09:14:27,373 : INFO : EPOCH 10 - PROGRESS: at 80.56% examples, 1209376 words/s, in_qsize 29, out_qsize 2\n",
      "2019-04-21 09:14:28,373 : INFO : EPOCH 10 - PROGRESS: at 88.79% examples, 1211984 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:29,379 : INFO : EPOCH 10 - PROGRESS: at 97.04% examples, 1214136 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:29,646 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-04-21 09:14:29,650 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-04-21 09:14:29,658 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-04-21 09:14:29,661 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-04-21 09:14:29,668 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-04-21 09:14:29,670 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-04-21 09:14:29,673 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-04-21 09:14:29,679 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-04-21 09:14:29,680 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-21 09:14:29,685 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-21 09:14:29,686 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-21 09:14:29,691 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-21 09:14:29,701 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-21 09:14:29,706 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-21 09:14:29,707 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-21 09:14:29,711 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-21 09:14:29,711 : INFO : EPOCH - 10 : training on 21030083 raw words (15071635 effective words) took 12.4s, 1217517 effective words/s\n",
      "2019-04-21 09:14:30,723 : INFO : EPOCH 11 - PROGRESS: at 7.22% examples, 1085058 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:31,730 : INFO : EPOCH 11 - PROGRESS: at 15.36% examples, 1151138 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:32,735 : INFO : EPOCH 11 - PROGRESS: at 23.48% examples, 1173283 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:33,738 : INFO : EPOCH 11 - PROGRESS: at 31.58% examples, 1185311 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:34,743 : INFO : EPOCH 11 - PROGRESS: at 39.66% examples, 1190595 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:14:35,755 : INFO : EPOCH 11 - PROGRESS: at 47.91% examples, 1197334 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:36,763 : INFO : EPOCH 11 - PROGRESS: at 56.13% examples, 1201819 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:37,771 : INFO : EPOCH 11 - PROGRESS: at 64.36% examples, 1205307 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:38,776 : INFO : EPOCH 11 - PROGRESS: at 72.63% examples, 1209087 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:39,778 : INFO : EPOCH 11 - PROGRESS: at 80.52% examples, 1206689 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:40,782 : INFO : EPOCH 11 - PROGRESS: at 88.70% examples, 1208482 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:14:41,784 : INFO : EPOCH 11 - PROGRESS: at 96.81% examples, 1209535 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:42,093 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-04-21 09:14:42,098 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-04-21 09:14:42,102 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-04-21 09:14:42,107 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-04-21 09:14:42,114 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-04-21 09:14:42,116 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-04-21 09:14:42,117 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-04-21 09:14:42,119 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-04-21 09:14:42,130 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-21 09:14:42,132 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-21 09:14:42,136 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-21 09:14:42,139 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-21 09:14:42,140 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-21 09:14:42,148 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-21 09:14:42,149 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-21 09:14:42,149 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-21 09:14:42,150 : INFO : EPOCH - 11 : training on 21030083 raw words (15073200 effective words) took 12.4s, 1212575 effective words/s\n",
      "2019-04-21 09:14:43,165 : INFO : EPOCH 12 - PROGRESS: at 6.94% examples, 1039501 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:44,168 : INFO : EPOCH 12 - PROGRESS: at 15.07% examples, 1130023 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:45,172 : INFO : EPOCH 12 - PROGRESS: at 23.34% examples, 1166621 words/s, in_qsize 29, out_qsize 2\n",
      "2019-04-21 09:14:46,176 : INFO : EPOCH 12 - PROGRESS: at 31.54% examples, 1183498 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:47,181 : INFO : EPOCH 12 - PROGRESS: at 39.71% examples, 1192006 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:48,185 : INFO : EPOCH 12 - PROGRESS: at 47.87% examples, 1197759 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:49,200 : INFO : EPOCH 12 - PROGRESS: at 55.85% examples, 1196031 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:50,208 : INFO : EPOCH 12 - PROGRESS: at 64.08% examples, 1200097 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:14:51,210 : INFO : EPOCH 12 - PROGRESS: at 72.20% examples, 1202655 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:52,212 : INFO : EPOCH 12 - PROGRESS: at 80.14% examples, 1201682 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:14:53,212 : INFO : EPOCH 12 - PROGRESS: at 88.36% examples, 1205049 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:54,214 : INFO : EPOCH 12 - PROGRESS: at 96.57% examples, 1207568 words/s, in_qsize 29, out_qsize 2\n",
      "2019-04-21 09:14:54,546 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-04-21 09:14:54,555 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-04-21 09:14:54,559 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-04-21 09:14:54,561 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-04-21 09:14:54,569 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-04-21 09:14:54,571 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-04-21 09:14:54,575 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-04-21 09:14:54,578 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-04-21 09:14:54,585 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-21 09:14:54,591 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-21 09:14:54,592 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-21 09:14:54,593 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-21 09:14:54,594 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-21 09:14:54,595 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-21 09:14:54,598 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-21 09:14:54,599 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-21 09:14:54,599 : INFO : EPOCH - 12 : training on 21030083 raw words (15075295 effective words) took 12.4s, 1211724 effective words/s\n",
      "2019-04-21 09:14:55,612 : INFO : EPOCH 13 - PROGRESS: at 7.22% examples, 1083511 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:56,621 : INFO : EPOCH 13 - PROGRESS: at 15.22% examples, 1138511 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:57,626 : INFO : EPOCH 13 - PROGRESS: at 23.43% examples, 1170044 words/s, in_qsize 31, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-21 09:14:58,628 : INFO : EPOCH 13 - PROGRESS: at 31.58% examples, 1184597 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:14:59,639 : INFO : EPOCH 13 - PROGRESS: at 39.71% examples, 1189874 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:15:00,642 : INFO : EPOCH 13 - PROGRESS: at 47.77% examples, 1193829 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:01,653 : INFO : EPOCH 13 - PROGRESS: at 56.04% examples, 1199238 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:02,662 : INFO : EPOCH 13 - PROGRESS: at 64.31% examples, 1203746 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:03,669 : INFO : EPOCH 13 - PROGRESS: at 72.58% examples, 1207489 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:04,671 : INFO : EPOCH 13 - PROGRESS: at 80.75% examples, 1209525 words/s, in_qsize 29, out_qsize 2\n",
      "2019-04-21 09:15:05,685 : INFO : EPOCH 13 - PROGRESS: at 88.88% examples, 1209384 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:06,689 : INFO : EPOCH 13 - PROGRESS: at 97.00% examples, 1210195 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:15:06,962 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-04-21 09:15:06,975 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-04-21 09:15:06,976 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-04-21 09:15:06,982 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-04-21 09:15:06,991 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-04-21 09:15:06,993 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-04-21 09:15:07,001 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-04-21 09:15:07,012 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-04-21 09:15:07,021 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-21 09:15:07,021 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-21 09:15:07,024 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-21 09:15:07,029 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-21 09:15:07,035 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-21 09:15:07,037 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-21 09:15:07,038 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-21 09:15:07,040 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-21 09:15:07,040 : INFO : EPOCH - 13 : training on 21030083 raw words (15072318 effective words) took 12.4s, 1212353 effective words/s\n",
      "2019-04-21 09:15:08,053 : INFO : EPOCH 14 - PROGRESS: at 7.32% examples, 1097360 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:15:09,055 : INFO : EPOCH 14 - PROGRESS: at 15.45% examples, 1160398 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:15:10,066 : INFO : EPOCH 14 - PROGRESS: at 23.53% examples, 1174444 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:11,074 : INFO : EPOCH 14 - PROGRESS: at 31.58% examples, 1182714 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:12,074 : INFO : EPOCH 14 - PROGRESS: at 39.33% examples, 1179641 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:13,078 : INFO : EPOCH 14 - PROGRESS: at 47.58% examples, 1189865 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:14,078 : INFO : EPOCH 14 - PROGRESS: at 55.80% examples, 1196596 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:15,086 : INFO : EPOCH 14 - PROGRESS: at 63.93% examples, 1198918 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:16,090 : INFO : EPOCH 14 - PROGRESS: at 72.11% examples, 1202059 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:17,095 : INFO : EPOCH 14 - PROGRESS: at 80.14% examples, 1202164 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:18,105 : INFO : EPOCH 14 - PROGRESS: at 88.41% examples, 1205148 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:19,110 : INFO : EPOCH 14 - PROGRESS: at 96.62% examples, 1207343 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:19,437 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-04-21 09:15:19,438 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-04-21 09:15:19,443 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-04-21 09:15:19,445 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-04-21 09:15:19,453 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-04-21 09:15:19,455 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-04-21 09:15:19,458 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-04-21 09:15:19,461 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-04-21 09:15:19,466 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-21 09:15:19,467 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-21 09:15:19,468 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-21 09:15:19,472 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-21 09:15:19,474 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-21 09:15:19,475 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-21 09:15:19,483 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-21 09:15:19,486 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-21 09:15:19,486 : INFO : EPOCH - 14 : training on 21030083 raw words (15072860 effective words) took 12.4s, 1211820 effective words/s\n",
      "2019-04-21 09:15:20,502 : INFO : EPOCH 15 - PROGRESS: at 7.27% examples, 1088257 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:21,505 : INFO : EPOCH 15 - PROGRESS: at 15.31% examples, 1147538 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:22,512 : INFO : EPOCH 15 - PROGRESS: at 23.39% examples, 1167856 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:15:23,519 : INFO : EPOCH 15 - PROGRESS: at 31.58% examples, 1183572 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:24,530 : INFO : EPOCH 15 - PROGRESS: at 39.75% examples, 1190470 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:25,531 : INFO : EPOCH 15 - PROGRESS: at 48.01% examples, 1199504 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:15:26,548 : INFO : EPOCH 15 - PROGRESS: at 56.27% examples, 1203107 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:27,550 : INFO : EPOCH 15 - PROGRESS: at 64.50% examples, 1207233 words/s, in_qsize 32, out_qsize 0\n",
      "2019-04-21 09:15:28,553 : INFO : EPOCH 15 - PROGRESS: at 72.63% examples, 1208713 words/s, in_qsize 30, out_qsize 1\n",
      "2019-04-21 09:15:29,556 : INFO : EPOCH 15 - PROGRESS: at 80.80% examples, 1210622 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:30,562 : INFO : EPOCH 15 - PROGRESS: at 88.84% examples, 1209937 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:31,571 : INFO : EPOCH 15 - PROGRESS: at 96.76% examples, 1207871 words/s, in_qsize 31, out_qsize 0\n",
      "2019-04-21 09:15:31,880 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2019-04-21 09:15:31,884 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2019-04-21 09:15:31,887 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2019-04-21 09:15:31,891 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2019-04-21 09:15:31,892 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2019-04-21 09:15:31,893 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2019-04-21 09:15:31,904 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2019-04-21 09:15:31,910 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2019-04-21 09:15:31,919 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-04-21 09:15:31,920 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-04-21 09:15:31,921 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-04-21 09:15:31,928 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-04-21 09:15:31,932 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-21 09:15:31,935 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-21 09:15:31,938 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-21 09:15:31,943 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-21 09:15:31,944 : INFO : EPOCH - 15 : training on 21030083 raw words (15074400 effective words) took 12.4s, 1210858 effective words/s\n",
      "2019-04-21 09:15:31,944 : INFO : training on a 315451245 raw words (226097042 effective words) took 187.0s, 1209144 effective words/s\n"
     ]
    }
   ],
   "source": [
    "import gensim, logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "word2vec_model = gensim.models.Word2Vec(doc_lst, min_count=3, size=EMBEDDING_DIM, sg=1, workers=os.cpu_count(), iter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 6000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "# f = open(\"glove.6B.100d.txt\",\"r\")\n",
    "# for line in f:\n",
    "#     values = line.split()\n",
    "#     word = values[0]\n",
    "#     coefs = np.asarray(values[1:], dtype='float32')\n",
    "#     embeddings_index[word] = coefs\n",
    "# f.close()\n",
    "    \n",
    "\n",
    "for word in word2vec_model.wv.vocab:\n",
    "    coefs = np.asarray(word2vec_model.wv[word], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "print('Total %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((MAX_NB_WORDS + 1, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None and i < MAX_NB_WORDS:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    elif i == MAX_NB_WORDS:\n",
    "        embedding_matrix[i] = embeddings_index['UNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "REG_PARAM = 1e-5\n",
    "l2_reg = regularizers.l2(REG_PARAM)\n",
    "\n",
    "embedding_layer = Embedding(MAX_NB_WORDS+ 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            input_length=MAX_SENT_LENGTH,\n",
    "                            trainable=True,\n",
    "                            mask_zero=False,\n",
    "                            embeddings_regularizer=l2_reg,\n",
    "                            weights=[embedding_matrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_DIM = 100\n",
    "\n",
    "class AttLayer(Layer):\n",
    "    def __init__(self, regularizer=None, **kwargs):\n",
    "        self.regularizer = regularizer\n",
    "        self.supports_masking = True\n",
    "        super(AttLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3        \n",
    "        self.W = self.add_weight(name='W', shape=(input_shape[-1], CONTEXT_DIM), initializer='normal', trainable=True, \n",
    "                                 regularizer=self.regularizer)\n",
    "        self.b = self.add_weight(name='b', shape=(CONTEXT_DIM,), initializer='normal', trainable=True, \n",
    "                                 regularizer=self.regularizer)\n",
    "        self.u = self.add_weight(name='u', shape=(CONTEXT_DIM,), initializer='normal', trainable=True, \n",
    "                                 regularizer=self.regularizer)        \n",
    "        super(AttLayer, self).build(input_shape)  # be sure you call this somewhere!\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        eij = K.dot(K.tanh(K.dot(x, self.W) + self.b), K.expand_dims(self.u))\n",
    "        ai = K.exp(eij)\n",
    "        alphas = ai / K.sum(ai, axis=1)\n",
    "        if mask is not None:\n",
    "            # use only the inputs specified by the mask\n",
    "            alphas *= K.expand_dims(mask)\n",
    "        weighted_input = K.dot(K.transpose(x), alphas)\n",
    "        return K.reshape(weighted_input, (weighted_input.shape[0],))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = {}\n",
    "        base_config = super(AttLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_mask(self, inputs, mask):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GPU_IMPL = 2          \n",
    "GRU_UNITS = 100        \n",
    "\n",
    "sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sentence_input)\n",
    "l_lstm = GRU(GRU_UNITS, return_sequences=True, kernel_regularizer=l2_reg, \n",
    "                           implementation=GPU_IMPL, recurrent_activation='sigmoid')(embedded_sequences)\n",
    "l_att = AttLayer(regularizer=l2_reg)(l_lstm)            \n",
    "sentEncoder = Model(sentence_input, l_att)\n",
    "\n",
    "review_input = Input(shape=(MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
    "review_encoder = TimeDistributed(sentEncoder)(review_input)\n",
    "l_lstm_sent = GRU(GRU_UNITS, return_sequences=True, kernel_regularizer=l2_reg, \n",
    "                                implementation=GPU_IMPL, recurrent_activation='sigmoid')(review_encoder)\n",
    "l_att_sent = AttLayer(regularizer=l2_reg)(l_lstm_sent)\n",
    "dense = Dense(500, activation='sigmoid', kernel_regularizer=l2_reg)(l_att_sent)\n",
    "preds = Dense(n_classes, activation='softmax', kernel_regularizer=l2_reg)(dense)\n",
    "model = Model(review_input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=0.1,nesterov=True, clipnorm=1.0),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10, 25)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 10, 100)           670600    \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 10, 100)           60300     \n",
      "_________________________________________________________________\n",
      "att_layer_2 (AttLayer)       (None, 100)               10200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               50500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 54)                27054     \n",
      "=================================================================\n",
      "Total params: 818,654\n",
      "Trainable params: 818,654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'det'\n",
    "history = History()\n",
    "csv_logger = CSVLogger('./{0}_{1}.log'.format(fname, REG_PARAM), separator=',', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_lengths = [len(r) for r in reviews]\n",
    "ind = np.argsort(doc_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 30\n",
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"models/saved-model6-{epoch:02d}-{acc:.2f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 187566 samples, validate on 20841 samples\n",
      "Epoch 1/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 4.0508 - acc: 0.1513Epoch 00000: val_acc improved from -inf to 0.09793, saving model to models/saved-model6-00-0.15.h5\n",
      "187566/187566 [==============================] - 147s - loss: 4.0508 - acc: 0.1513 - val_loss: 6.5634 - val_acc: 0.0979\n",
      "Epoch 2/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 3.0540 - acc: 0.3534Epoch 00001: val_acc improved from 0.09793 to 0.27969, saving model to models/saved-model6-01-0.35.h5\n",
      "187566/187566 [==============================] - 148s - loss: 3.0541 - acc: 0.3534 - val_loss: 3.6169 - val_acc: 0.2797\n",
      "Epoch 3/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 2.7442 - acc: 0.4209Epoch 00002: val_acc improved from 0.27969 to 0.33914, saving model to models/saved-model6-02-0.42.h5\n",
      "187566/187566 [==============================] - 152s - loss: 2.7442 - acc: 0.4210 - val_loss: 3.1582 - val_acc: 0.3391\n",
      "Epoch 4/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 2.6065 - acc: 0.4539Epoch 00003: val_acc improved from 0.33914 to 0.36179, saving model to models/saved-model6-03-0.45.h5\n",
      "187566/187566 [==============================] - 152s - loss: 2.6065 - acc: 0.4539 - val_loss: 3.0314 - val_acc: 0.3618\n",
      "Epoch 5/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 2.5152 - acc: 0.4769Epoch 00004: val_acc improved from 0.36179 to 0.37848, saving model to models/saved-model6-04-0.48.h5\n",
      "187566/187566 [==============================] - 147s - loss: 2.5153 - acc: 0.4769 - val_loss: 2.9588 - val_acc: 0.3785\n",
      "Epoch 6/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 2.4442 - acc: 0.4932Epoch 00005: val_acc improved from 0.37848 to 0.40084, saving model to models/saved-model6-05-0.49.h5\n",
      "187566/187566 [==============================] - 148s - loss: 2.4442 - acc: 0.4932 - val_loss: 2.8576 - val_acc: 0.4008\n",
      "Epoch 7/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 2.3858 - acc: 0.5068Epoch 00006: val_acc improved from 0.40084 to 0.41663, saving model to models/saved-model6-06-0.51.h5\n",
      "187566/187566 [==============================] - 149s - loss: 2.3858 - acc: 0.5069 - val_loss: 2.7830 - val_acc: 0.4166\n",
      "Epoch 8/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 2.3366 - acc: 0.5183Epoch 00007: val_acc improved from 0.41663 to 0.41913, saving model to models/saved-model6-07-0.52.h5\n",
      "187566/187566 [==============================] - 148s - loss: 2.3366 - acc: 0.5183 - val_loss: 2.7512 - val_acc: 0.4191\n",
      "Epoch 9/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 2.2924 - acc: 0.5285Epoch 00008: val_acc improved from 0.41913 to 0.42819, saving model to models/saved-model6-08-0.53.h5\n",
      "187566/187566 [==============================] - 148s - loss: 2.2924 - acc: 0.5285 - val_loss: 2.7046 - val_acc: 0.4282\n",
      "Epoch 10/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 2.2527 - acc: 0.5370Epoch 00009: val_acc improved from 0.42819 to 0.44225, saving model to models/saved-model6-09-0.54.h5\n",
      "187566/187566 [==============================] - 148s - loss: 2.2527 - acc: 0.5370 - val_loss: 2.6535 - val_acc: 0.4423\n",
      "Epoch 11/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 2.2164 - acc: 0.5452Epoch 00010: val_acc improved from 0.44225 to 0.44768, saving model to models/saved-model6-10-0.55.h5\n",
      "187566/187566 [==============================] - 147s - loss: 2.2164 - acc: 0.5452 - val_loss: 2.6225 - val_acc: 0.4477\n",
      "Epoch 12/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 2.1817 - acc: 0.5531Epoch 00011: val_acc improved from 0.44768 to 0.45583, saving model to models/saved-model6-11-0.55.h5\n",
      "187566/187566 [==============================] - 148s - loss: 2.1817 - acc: 0.5531 - val_loss: 2.5892 - val_acc: 0.4558\n",
      "Epoch 13/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 2.1491 - acc: 0.5599Epoch 00012: val_acc improved from 0.45583 to 0.46068, saving model to models/saved-model6-12-0.56.h5\n",
      "187566/187566 [==============================] - 148s - loss: 2.1492 - acc: 0.5599 - val_loss: 2.5524 - val_acc: 0.4607\n",
      "Epoch 14/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 2.1187 - acc: 0.5661Epoch 00013: val_acc improved from 0.46068 to 0.46850, saving model to models/saved-model6-13-0.57.h5\n",
      "187566/187566 [==============================] - 148s - loss: 2.1187 - acc: 0.5661 - val_loss: 2.5178 - val_acc: 0.4685\n",
      "Epoch 15/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 2.0891 - acc: 0.5725Epoch 00014: val_acc improved from 0.46850 to 0.47512, saving model to models/saved-model6-14-0.57.h5\n",
      "187566/187566 [==============================] - 147s - loss: 2.0892 - acc: 0.5725 - val_loss: 2.4907 - val_acc: 0.4751\n",
      "Epoch 16/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 2.0612 - acc: 0.5793Epoch 00015: val_acc improved from 0.47512 to 0.47584, saving model to models/saved-model6-15-0.58.h5\n",
      "187566/187566 [==============================] - 148s - loss: 2.0612 - acc: 0.5793 - val_loss: 2.4874 - val_acc: 0.4758\n",
      "Epoch 17/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 2.0343 - acc: 0.5850Epoch 00016: val_acc improved from 0.47584 to 0.48011, saving model to models/saved-model6-16-0.59.h5\n",
      "187566/187566 [==============================] - 148s - loss: 2.0344 - acc: 0.5850 - val_loss: 2.4759 - val_acc: 0.4801\n",
      "Epoch 18/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 2.0082 - acc: 0.5905Epoch 00017: val_acc improved from 0.48011 to 0.48659, saving model to models/saved-model6-17-0.59.h5\n",
      "187566/187566 [==============================] - 148s - loss: 2.0082 - acc: 0.5905 - val_loss: 2.4490 - val_acc: 0.4866\n",
      "Epoch 19/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.9824 - acc: 0.5975Epoch 00018: val_acc improved from 0.48659 to 0.49067, saving model to models/saved-model6-18-0.60.h5\n",
      "187566/187566 [==============================] - 147s - loss: 1.9825 - acc: 0.5975 - val_loss: 2.4395 - val_acc: 0.4907\n",
      "Epoch 20/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.9574 - acc: 0.6034Epoch 00019: val_acc did not improve\n",
      "187566/187566 [==============================] - 148s - loss: 1.9573 - acc: 0.6034 - val_loss: 2.4298 - val_acc: 0.4903\n",
      "Epoch 21/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.9335 - acc: 0.6091Epoch 00020: val_acc improved from 0.49067 to 0.49484, saving model to models/saved-model6-20-0.61.h5\n",
      "187566/187566 [==============================] - 147s - loss: 1.9335 - acc: 0.6091 - val_loss: 2.4176 - val_acc: 0.4948\n",
      "Epoch 22/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.9101 - acc: 0.6141Epoch 00021: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.9101 - acc: 0.6141 - val_loss: 2.4115 - val_acc: 0.4944\n",
      "Epoch 23/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.8873 - acc: 0.6194Epoch 00022: val_acc improved from 0.49484 to 0.50170, saving model to models/saved-model6-22-0.62.h5\n",
      "187566/187566 [==============================] - 148s - loss: 1.8873 - acc: 0.6194 - val_loss: 2.3974 - val_acc: 0.5017\n",
      "Epoch 24/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.8646 - acc: 0.6256Epoch 00023: val_acc did not improve\n",
      "187566/187566 [==============================] - 150s - loss: 1.8647 - acc: 0.6256 - val_loss: 2.4232 - val_acc: 0.4959\n",
      "Epoch 25/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.8430 - acc: 0.6304Epoch 00024: val_acc did not improve\n",
      "187566/187566 [==============================] - 151s - loss: 1.8430 - acc: 0.6304 - val_loss: 2.4162 - val_acc: 0.5004\n",
      "Epoch 26/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.8229 - acc: 0.6351Epoch 00025: val_acc did not improve\n",
      "187566/187566 [==============================] - 151s - loss: 1.8229 - acc: 0.6351 - val_loss: 2.4236 - val_acc: 0.4998\n",
      "Epoch 27/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.8029 - acc: 0.6402Epoch 00026: val_acc did not improve\n",
      "187566/187566 [==============================] - 153s - loss: 1.8030 - acc: 0.6402 - val_loss: 2.4176 - val_acc: 0.5015\n",
      "Epoch 28/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.7820 - acc: 0.6451Epoch 00027: val_acc did not improve\n",
      "187566/187566 [==============================] - 148s - loss: 1.7821 - acc: 0.6451 - val_loss: 2.4480 - val_acc: 0.4992\n",
      "Epoch 29/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.7650 - acc: 0.6496Epoch 00028: val_acc improved from 0.50170 to 0.50214, saving model to models/saved-model6-28-0.65.h5\n",
      "187566/187566 [==============================] - 147s - loss: 1.7650 - acc: 0.6496 - val_loss: 2.4345 - val_acc: 0.5021\n",
      "Epoch 30/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.7456 - acc: 0.6541Epoch 00029: val_acc did not improve\n",
      "187566/187566 [==============================] - 148s - loss: 1.7456 - acc: 0.6541 - val_loss: 2.4659 - val_acc: 0.4959\n",
      "Epoch 31/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.7291 - acc: 0.6579Epoch 00030: val_acc improved from 0.50214 to 0.50348, saving model to models/saved-model6-30-0.66.h5\n",
      "187566/187566 [==============================] - 147s - loss: 1.7291 - acc: 0.6579 - val_loss: 2.4389 - val_acc: 0.5035\n",
      "Epoch 32/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.7117 - acc: 0.6625Epoch 00031: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.7117 - acc: 0.6625 - val_loss: 2.4687 - val_acc: 0.5008\n",
      "Epoch 33/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.6952 - acc: 0.6662Epoch 00032: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.6952 - acc: 0.6662 - val_loss: 2.4667 - val_acc: 0.5013\n",
      "Epoch 34/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.6798 - acc: 0.6708Epoch 00033: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.6798 - acc: 0.6708 - val_loss: 2.4715 - val_acc: 0.5030\n",
      "Epoch 35/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.6636 - acc: 0.6751Epoch 00034: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.6636 - acc: 0.6751 - val_loss: 2.4778 - val_acc: 0.5034\n",
      "Epoch 36/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.6486 - acc: 0.6776Epoch 00035: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.6485 - acc: 0.6776 - val_loss: 2.4834 - val_acc: 0.5023\n",
      "Epoch 37/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.6336 - acc: 0.6819Epoch 00036: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.6336 - acc: 0.6819 - val_loss: 2.4924 - val_acc: 0.5032\n",
      "Epoch 38/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.6194 - acc: 0.6854Epoch 00037: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.6194 - acc: 0.6854 - val_loss: 2.5039 - val_acc: 0.5021\n",
      "Epoch 39/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.6042 - acc: 0.6896Epoch 00038: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.6042 - acc: 0.6896 - val_loss: 2.5168 - val_acc: 0.5010\n",
      "Epoch 40/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.5903 - acc: 0.6931Epoch 00039: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.5903 - acc: 0.6931 - val_loss: 2.5273 - val_acc: 0.5016\n",
      "Epoch 41/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.5777 - acc: 0.6969Epoch 00040: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.5777 - acc: 0.6969 - val_loss: 2.5533 - val_acc: 0.4980\n",
      "Epoch 42/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.5630 - acc: 0.6998Epoch 00041: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.5631 - acc: 0.6998 - val_loss: 2.5596 - val_acc: 0.4979\n",
      "Epoch 43/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.5502 - acc: 0.7041Epoch 00042: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.5502 - acc: 0.7040 - val_loss: 2.5510 - val_acc: 0.4992\n",
      "Epoch 44/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.5385 - acc: 0.7073Epoch 00043: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.5386 - acc: 0.7073 - val_loss: 2.5726 - val_acc: 0.4976\n",
      "Epoch 45/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.5262 - acc: 0.7107Epoch 00044: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.5262 - acc: 0.7107 - val_loss: 2.5914 - val_acc: 0.4978\n",
      "Epoch 46/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.5137 - acc: 0.7140Epoch 00045: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.5138 - acc: 0.7140 - val_loss: 2.6065 - val_acc: 0.4988\n",
      "Epoch 47/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.5020 - acc: 0.7176Epoch 00046: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.5020 - acc: 0.7176 - val_loss: 2.6147 - val_acc: 0.4965\n",
      "Epoch 48/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.4894 - acc: 0.7199Epoch 00047: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.4895 - acc: 0.7199 - val_loss: 2.6235 - val_acc: 0.4955\n",
      "Epoch 49/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.4798 - acc: 0.7228Epoch 00048: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.4798 - acc: 0.7228 - val_loss: 2.6264 - val_acc: 0.4969\n",
      "Epoch 50/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.4688 - acc: 0.7259Epoch 00049: val_acc did not improve\n",
      "187566/187566 [==============================] - 148s - loss: 1.4688 - acc: 0.7259 - val_loss: 2.6327 - val_acc: 0.4954\n",
      "Epoch 51/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.4581 - acc: 0.7283Epoch 00050: val_acc did not improve\n",
      "187566/187566 [==============================] - 148s - loss: 1.4581 - acc: 0.7283 - val_loss: 2.6558 - val_acc: 0.4931\n",
      "Epoch 52/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.4479 - acc: 0.7313Epoch 00051: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.4480 - acc: 0.7313 - val_loss: 2.6567 - val_acc: 0.4955\n",
      "Epoch 53/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.4371 - acc: 0.7354Epoch 00052: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.4371 - acc: 0.7354 - val_loss: 2.6786 - val_acc: 0.4942\n",
      "Epoch 54/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.4253 - acc: 0.7387Epoch 00053: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.4253 - acc: 0.7387 - val_loss: 2.6951 - val_acc: 0.4952\n",
      "Epoch 55/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.4154 - acc: 0.7402Epoch 00054: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.4155 - acc: 0.7402 - val_loss: 2.6990 - val_acc: 0.4977\n",
      "Epoch 56/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.4070 - acc: 0.7414Epoch 00055: val_acc did not improve\n",
      "187566/187566 [==============================] - 148s - loss: 1.4071 - acc: 0.7414 - val_loss: 2.7058 - val_acc: 0.4977\n",
      "Epoch 57/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.3971 - acc: 0.7451Epoch 00056: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.3971 - acc: 0.7451 - val_loss: 2.7167 - val_acc: 0.4982\n",
      "Epoch 58/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.3891 - acc: 0.7468Epoch 00057: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.3891 - acc: 0.7468 - val_loss: 2.7420 - val_acc: 0.4941\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.3759 - acc: 0.7502Epoch 00058: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.3759 - acc: 0.7502 - val_loss: 2.7307 - val_acc: 0.4957\n",
      "Epoch 60/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.3694 - acc: 0.7521Epoch 00059: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.3694 - acc: 0.7521 - val_loss: 2.7366 - val_acc: 0.4956\n",
      "Epoch 61/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.3581 - acc: 0.7557Epoch 00060: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.3582 - acc: 0.7557 - val_loss: 2.7521 - val_acc: 0.4970\n",
      "Epoch 62/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.3483 - acc: 0.7591Epoch 00061: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.3483 - acc: 0.7591 - val_loss: 2.7760 - val_acc: 0.4949\n",
      "Epoch 63/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.3387 - acc: 0.7608Epoch 00062: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.3388 - acc: 0.7608 - val_loss: 2.7874 - val_acc: 0.4978\n",
      "Epoch 64/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.3337 - acc: 0.7622Epoch 00063: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.3337 - acc: 0.7622 - val_loss: 2.7845 - val_acc: 0.4975\n",
      "Epoch 65/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.3227 - acc: 0.7653Epoch 00064: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.3228 - acc: 0.7653 - val_loss: 2.8191 - val_acc: 0.4941\n",
      "Epoch 66/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.3135 - acc: 0.7683Epoch 00065: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.3135 - acc: 0.7683 - val_loss: 2.8190 - val_acc: 0.4948\n",
      "Epoch 67/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.3042 - acc: 0.7704Epoch 00066: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.3042 - acc: 0.7704 - val_loss: 2.8174 - val_acc: 0.4949\n",
      "Epoch 68/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.2972 - acc: 0.7711Epoch 00067: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.2973 - acc: 0.7711 - val_loss: 2.8333 - val_acc: 0.4941\n",
      "Epoch 69/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.2901 - acc: 0.7737Epoch 00068: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.2901 - acc: 0.7737 - val_loss: 2.8490 - val_acc: 0.4940\n",
      "Epoch 70/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.2826 - acc: 0.7758Epoch 00069: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.2826 - acc: 0.7758 - val_loss: 2.8507 - val_acc: 0.4927\n",
      "Epoch 71/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.2723 - acc: 0.7783Epoch 00070: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.2724 - acc: 0.7783 - val_loss: 2.8645 - val_acc: 0.4951\n",
      "Epoch 72/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.2723 - acc: 0.7783Epoch 00071: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.2723 - acc: 0.7783 - val_loss: 2.9045 - val_acc: 0.4933\n",
      "Epoch 73/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.2576 - acc: 0.7826Epoch 00072: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.2576 - acc: 0.7826 - val_loss: 2.8823 - val_acc: 0.4944\n",
      "Epoch 74/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.2495 - acc: 0.7857Epoch 00073: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.2495 - acc: 0.7857 - val_loss: 2.8862 - val_acc: 0.4984\n",
      "Epoch 75/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.2418 - acc: 0.7867Epoch 00074: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.2419 - acc: 0.7867 - val_loss: 2.8823 - val_acc: 0.4979\n",
      "Epoch 76/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.2342 - acc: 0.7884Epoch 00075: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.2343 - acc: 0.7884 - val_loss: 2.9156 - val_acc: 0.4957\n",
      "Epoch 77/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.2269 - acc: 0.7904Epoch 00076: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.2269 - acc: 0.7904 - val_loss: 2.9334 - val_acc: 0.4970\n",
      "Epoch 78/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.2183 - acc: 0.7927Epoch 00077: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.2183 - acc: 0.7927 - val_loss: 2.9338 - val_acc: 0.4953\n",
      "Epoch 79/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.2113 - acc: 0.7950Epoch 00078: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.2113 - acc: 0.7950 - val_loss: 2.9506 - val_acc: 0.4968\n",
      "Epoch 80/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.2051 - acc: 0.7965Epoch 00079: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.2051 - acc: 0.7965 - val_loss: 2.9638 - val_acc: 0.4968\n",
      "Epoch 81/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.1982 - acc: 0.7988Epoch 00080: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.1982 - acc: 0.7988 - val_loss: 2.9866 - val_acc: 0.4933\n",
      "Epoch 82/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.1919 - acc: 0.8000Epoch 00081: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.1919 - acc: 0.7999 - val_loss: 2.9738 - val_acc: 0.4969\n",
      "Epoch 83/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.1830 - acc: 0.8015Epoch 00082: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.1830 - acc: 0.8015 - val_loss: 3.0085 - val_acc: 0.4938\n",
      "Epoch 84/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.1755 - acc: 0.8042Epoch 00083: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.1756 - acc: 0.8041 - val_loss: 3.0000 - val_acc: 0.4953\n",
      "Epoch 85/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.1717 - acc: 0.8047Epoch 00084: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.1717 - acc: 0.8047 - val_loss: 3.0154 - val_acc: 0.4970\n",
      "Epoch 86/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.1636 - acc: 0.8066Epoch 00085: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.1636 - acc: 0.8066 - val_loss: 3.0348 - val_acc: 0.4958\n",
      "Epoch 87/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.1565 - acc: 0.8094Epoch 00086: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.1565 - acc: 0.8094 - val_loss: 3.0490 - val_acc: 0.4926\n",
      "Epoch 88/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.1521 - acc: 0.8103Epoch 00087: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.1521 - acc: 0.8103 - val_loss: 3.0621 - val_acc: 0.4926\n",
      "Epoch 89/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.1440 - acc: 0.8129Epoch 00088: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.1441 - acc: 0.8129 - val_loss: 3.0567 - val_acc: 0.4965\n",
      "Epoch 90/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.1380 - acc: 0.8134Epoch 00089: val_acc did not improve\n",
      "187566/187566 [==============================] - 147s - loss: 1.1379 - acc: 0.8134 - val_loss: 3.0917 - val_acc: 0.4950\n",
      "Epoch 91/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.1322 - acc: 0.8158Epoch 00090: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.1322 - acc: 0.8158 - val_loss: 3.0987 - val_acc: 0.4912\n",
      "Epoch 92/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.1251 - acc: 0.8182Epoch 00091: val_acc did not improve\n",
      "187566/187566 [==============================] - 145s - loss: 1.1251 - acc: 0.8182 - val_loss: 3.1036 - val_acc: 0.4948\n",
      "Epoch 93/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.1191 - acc: 0.8187Epoch 00092: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.1191 - acc: 0.8186 - val_loss: 3.1108 - val_acc: 0.4923\n",
      "Epoch 94/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.1138 - acc: 0.8202Epoch 00093: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.1138 - acc: 0.8202 - val_loss: 3.1321 - val_acc: 0.4915\n",
      "Epoch 95/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.1066 - acc: 0.8226Epoch 00094: val_acc did not improve\n",
      "187566/187566 [==============================] - 145s - loss: 1.1066 - acc: 0.8226 - val_loss: 3.1460 - val_acc: 0.4886\n",
      "Epoch 96/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.1001 - acc: 0.8247Epoch 00095: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.1001 - acc: 0.8247 - val_loss: 3.1376 - val_acc: 0.4932\n",
      "Epoch 97/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.0947 - acc: 0.8253Epoch 00096: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.0947 - acc: 0.8253 - val_loss: 3.1752 - val_acc: 0.4931\n",
      "Epoch 98/100\n",
      "187560/187566 [============================>.] - ETA: 0s - loss: 1.0896 - acc: 0.8262Epoch 00097: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.0896 - acc: 0.8262 - val_loss: 3.1686 - val_acc: 0.4910\n",
      "Epoch 99/100\n",
      "187500/187566 [============================>.] - ETA: 0s - loss: 1.0822 - acc: 0.8280Epoch 00098: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.0822 - acc: 0.8280 - val_loss: 3.1869 - val_acc: 0.4937\n",
      "Epoch 100/100\n",
      "187530/187566 [============================>.] - ETA: 0s - loss: 1.0748 - acc: 0.8305Epoch 00099: val_acc did not improve\n",
      "187566/187566 [==============================] - 146s - loss: 1.0749 - acc: 0.8305 - val_loss: 3.1969 - val_acc: 0.4928\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "model.fit(x_train[ind,:,:], y_train[ind,:], epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, shuffle=False, validation_data=[x_test,y_test], \n",
    "          callbacks=[history, csv_logger, checkpoint], verbose=1)\n",
    "\n",
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.4927786574540569\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(x_test)\n",
    "print(\"Accuracy = {0}\".format(accuracy_score(y_test.argmax(axis=1),preds.argmax(axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy@5 = 0.9591190441917374\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for z,val in enumerate(y_test.argmax(axis=1)):\n",
    "    if val in (-preds[z]).argsort()[:15]:\n",
    "        i+=1\n",
    "print(\"Accuracy@15 = {0}\".format(i/len(x_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
